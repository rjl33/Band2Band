{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms \n",
    "from PIL import Image \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of raw features (32768, 15)\n",
      "Shape of shape-frequency-features (32768, 21)\n",
      "Shape of dispersion curves (32768, 20, 150)\n"
     ]
    }
   ],
   "source": [
    "# mat = sio.loadmat('bandgap_data.mat')\n",
    "# X_raw = mat['feature_raw'] # raw features\n",
    "# X_shapefreq = mat['feature_shapefreq'] # shape frequency features\n",
    "# dispersion = mat['dispersion'] # dispersion curves\n",
    "# print('Shape of raw features', X_raw.shape)\n",
    "# print('Shape of shape-frequency-features', X_shapefreq.shape)\n",
    "# print('Shape of dispersion curves', dispersion.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of dispersion curve is 32768$\\times$20$\\times$150, which means there are $2^32768$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_and_gaps(freq_centr, freq_gap, freq_range, size_min = 0.0):\n",
    "    \"\"\"Calculate whether a band gap exist in certain freq range\"\"\"\n",
    "    labels = (freq_centr>0).astype('int32')\n",
    "    freq_lower = freq_centr - 0.5 * freq_gap\n",
    "    freq_upper = freq_centr + 0.5 * freq_gap\n",
    "    labels_new = np.zeros((freq_centr.shape[0],freq_range.shape[0]))\n",
    "    max_gaps = np.zeros((freq_centr.shape[0],freq_range.shape[0]))\n",
    "    for i in range(labels_new.shape[1]):\n",
    "        labels_new[:,i] = ((np.fmin(freq_upper,freq_range[i,1])-np.fmax(freq_lower,freq_range[i,0])>size_min).astype('int32').sum(1)>0).astype('int32')\n",
    "        max_gaps[:,i] = (np.fmin(freq_upper,freq_range[i,1])-np.fmax(freq_lower,freq_range[i,0])).max(1)\n",
    "    \n",
    "    max_gaps = np.fmax(max_gaps,0)\n",
    "    return labels_new\n",
    "\n",
    "freq_gap_inplane = dispersion[:,1:,:].min(2)-dispersion[:,:dispersion.shape[1]-1,:].max(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label: (32768, 3)\n"
     ]
    }
   ],
   "source": [
    "# freq_centr_inplane = (dispersion[:,1:,:].min(2)+dispersion[:,:dispersion.shape[1]-1,:].max(2))/2\n",
    "# freq_gap_inplane[np.where(freq_gap_inplane<0.01)] = 0\n",
    "# freq_centr_inplane[np.where(freq_gap_inplane<0.01)] = 0\n",
    "\n",
    "# freq_range_inplane = np.array([[0,1000],[1000,2000],[2000,3000]])\n",
    "# labels = get_labels_and_gaps(freq_centr_inplane, freq_gap_inplane, freq_range_inplane, size_min = 0.0)\n",
    "\n",
    "# print('Shape of label:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m grid10\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m#Dataset class\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munitcellds\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X15: np.ndarray, y: np.ndarray, resize=\u001b[32m64\u001b[39m):\n\u001b[32m     22\u001b[39m         \u001b[38;5;28mself\u001b[39m.X15 = X15.astype(np.uint8)\n",
      "\u001b[31mNameError\u001b[39m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#Make Dataset Class for CNN\n",
    "#This jelper takes out 15 feature input array and makes our 10x10 unit cell (Needed for the CNN to have a picture)\n",
    "def expand_15_to_10x10(bits15):\n",
    "    #place the 15 features into the upper triangle \n",
    "    tri = np.zeros((5,5), dtype = np.uint8)\n",
    "    k = 0\n",
    "    for i in range(5):\n",
    "        for j in range(i, 5):\n",
    "            tri[i, j] = bits15[k]\n",
    "            k += 1\n",
    "    #enforce symmetry: copy the upper triangle to the lower triangle \n",
    "    tri = tri | tri.T\n",
    "    #enforce horiz/vert symmetry by tiling the 5x5 block \n",
    "    top = np.concatenate([tri, np.fliplr(tri)], axis=1)\n",
    "    #stack that with its top-bottom flip\n",
    "    grid10 = np.concatenate([top, np.flipud(top)], axis=0)\n",
    "    return grid10\n",
    "\n",
    "#Dataset class\n",
    "class UnitCellDS(Dataset):\n",
    "    def __init__(self, X15: np.ndarray, y: np.ndarray, resize=64):\n",
    "        self.X15 = X15.astype(np.uint8)\n",
    "        self.y = torch.from_numpy(y.astype(np.int64))\n",
    "        self.itm = transforms.Compose([\n",
    "            transforms.Resize(resize), \n",
    "            transforms.ToTensor(), \n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "\n",
    "    #returns size of so dataloader knows how many samples exist \n",
    "    def __len__(self):\n",
    "        return len(self.X15)\n",
    "    #This will build a training sample on demand\n",
    "    def __getitem__(self, i):\n",
    "        grid10 = expand_15_to_10x10(self.X15[i]) * 255 #0/255 image \n",
    "        img = Image.fromarray(grid10.astype(np.uint8), mode=\"L\")\n",
    "        x = self.itm(img)\n",
    "        y = self.y[i]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
